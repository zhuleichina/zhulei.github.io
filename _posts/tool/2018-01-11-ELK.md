---
layout: post
title: 基于ELK的日志系统
category: 工具
tags: [ELK , 日志系统]
description: ELK由Elasticsearch、Logstash和Kibana三部分组件组成。
---

# 基于ELK的日志系统

ELK由Elasticsearch、Logstash和Kibana三部分组件组成:

Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。

Logstash是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用.

kibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。

Logstash是重量级的日志收集工具，包含过滤器等对服务器本身有一定的性能影响。实际使用时也可以用Filebeat轻量级的日志收集工具来替代。

## 1 需求分析

需要明确日志收集的需求：
1. 日志源：收集谁的日志文件
2. 日志存储：日志服务器部署在哪里

对于nginx部署的网站来说，日志源如下：
```
/var/log/nginx/access.log
/var/log/nginx/error.log
```

一般来说，收集过多的日志文件会占用过多的存储和很多无用日志，一般会明确需要收集哪些日志；

对于日志服务器来说，如果没有专门的规划日志服务器，可以放置在负荷较少，空闲存储较大的服务器上。

## 2 ELK的安装

### 2.1 日志源所在服务器的安装

对于日志源服务器来说，仅需要安装Filebeat就可以了，使用rpm安装。
```
#将filebeat-5.6.4-x86_64.rpm拷贝到/opt目录下
#给予可执行权限
chmod +x /opt/filebeat-5.6.4-x86_64.rpm
#安装filebeat
rpm -ivh /opt/filebeat-5.6.4-x86_64.rpm
```
使用rpm安装后已经加到系统服务里了，常用的操作如下：
```
# 开启
service filebeat start
# 关闭
service filebeat stop
# 重启
service filebeat restart
# 查询状态
service filebeat status
```
开机启动设置方法如下：
```
# 设置开机启动
systemctl enable filebeat.service
```

### 2.2 日志服务器的安装

对于日志服务器来说，需要安装ElasticSearch和Kibana，我们也使用rpm安装
```
# 将elasticsearch-5.6.4.rpm/kibana-5.6.4-x86_64.rpm拷贝到/opt目录下
# 给予可执行权限
chmod +x /opt/elasticsearch-5.6.4.rpm 
chmod +x /opt/kibana-5.6.4-x86_64.rpm
# 安装ElasticSearch和Kibana
rpm -ivh /opt/elasticsearch-5.6.4.rpm
rpm -ivh /opt/kibana-5.6.4-x86_64.rpm
```

使用rpm安装后已经加到系统服务里了，常用的操作如下：
```
# 开启
service elasticsearch start
service kibana start
# 关闭
service elasticsearch stop
service kibana stop
# 重启
service elasticsearch restart
service kibana restart
# 查询状态
service elasticsearch status
service kibana status
```

开机启动设置方法如下：
```
# 设置开机启动
systemctl enable elasticsearch.service
systemctl enable kibana.service
```

## 3 ELK的配置

### 3.1 日志源服务器配置

filebeat日志文件为/etc/filebeat/filebeat.yml ,需要修改的配置项如下(以nginx需要收集的日志文件为例)：

```
vim /etc/filebeat/filebeat.yml

# 默认paths配置为：
  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    - /var/log/*.log

#修改paths配置为：
  paths:
    - /var/log/nginx/access.log
    - /var/log/nginx/error.log

# 默认elasticsearch配置为：
#-------------------------- Elasticsearch output ------------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  hosts: ["localhost:9200"]

修改配置为：
output.elasticsearch:
  # Array of hosts to connect to.
  hosts: ["192.168.0.1:9200"]
# 其中192.168.1.1为日志服务器的地址，都部署在本机可以不用改配置

# 我们还可以修改name配置项，作为日志源的标记
# The name of the shipper that publishes the network data. It can be used to group
# all the transactions sent by a single shipper in the web interface.
#name:
# 修改为：
name:nginx_log
```

### 3.2 日志服务器的配置

### elasticsearch的配置

elasticsearch的配置文件为：/etc/elasticsearch/elasticsearch.yml ,需要修改的配置项为：

```
vim /etc/elasticsearch/elasticsearch.yml

# 默认network配置文件为：
# ---------------------------------- Network -----------------------------------
# Set the bind address to a specific IP (IPv4 or IPv6):
#network.host: 192.168.0.1
# Set a custom port for HTTP:
#http.port: 9200

# 修改为：
network.host: 192.168.0.1
http.port: 9200

# 这样修改只能通过192.168.0.1:9200访问elasticsearch，如果需要本机所有IP的的9200端口都需要访问elasticsearch，可以修改为：
network.host: 0.0.0.0

```

### kibana的配置

kibana的配置文件为：/etc/kibana/kibana.yml，需要修改的配置项为：

```
vim /etc/kibana/kibana.yml

# 需要修改的配置项为：
#server.port: 5601
#server.host: "localhost"
# 需要修改为：
server.port: 5601
server.host: "192.168.0.1"

# 这样修改只能通过192.168.0.1:5601 访问kibana，如需本机所有IP的5601都需要访问kibana，可以修改为
server.host: "0.0.0.0"
```

## 4 ELK的使用

访问elasticsearch
```
# 浏览器打开如下地址,其中192.168.0.1为日志服务器的IP：
192.168.0.1:9200
```
elasticsearch成功启动会返回节点信息。

访问kibana
```
# 浏览器打开如下地址,其



中192.168.0.1为日志服务器的IP：
192.168.0.1:5601
```
kibana成功启动会返回kibana的索引配置界面,filebeat作为日志源的可以配置filebeat-*为默认索引。

## 5 ELK日志文件

当出现问题时需要查询ELK的日志文件，rpm安装的日志文件分布如下：
```
# filebeat日志
/var/log/filebeat/filebeat

# elasticsearch日志
/var/log/elasticsearch/elasticsearch_deprecation.log
/var/log/elasticsearch/elasticsearch_index_indexing_slowlog.log
/var/log/elasticsearch/elasticsearch_index_search_slowlog.log
/var/log/elasticsearch/elasticsearch.log

# kibana日志
/var/log/kibana/kibana.stdout
/var/log/kibana/kibana.stderr
```

## 5 elasticsearch索引清理

elasticsearch会时刻收集日志数据并产生索引文件，会占用大量的主机存储，如果日志文件不需要永久保存的话就需要定期清理。

查询所有索引
```
curl 'localhost:9200/_cat/indices?v'

health status index               store.size pri.store.size
yellow open   filebeat-2018.01.14     48.6mb         48.6mb
yellow open   filebeat-2018.01.12     61.9mb         61.9mb
yellow open   invoker                   810b           810b
yellow open   filebeat-2018.01.10     65.1mb         65.1mb
yellow open   filebeat-2018.01.13     59.6mb         59.6mb
yellow open   filebeat-2018.01.15       59mb           59mb
yellow open   filebeat-2018.01.11     76.7mb         76.7mb
yellow open   watcher_alarms            960b           960b
yellow open   watcher                127.4kb        127.4kb
yellow open   filebeat-2018.01.16      9.6mb          9.6mb
yellow open   .kibana                 17.6kb         17.6kb
```
index就是我们日志文件产生的索引。

删除索引
```
#删除某天
curl -XDELETE 'localhost:9200/filebeat-2018.01.10'

#删除某旬
curl -XDELETE 'localhost:9200/filebeat-2018.01.1*'

#删除某月
curl -XDELETE 'localhost:9200/filebeat-2018.01.*'
```
